{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"e8a9fb0142bb4534ac1e513ca01880c8","deepnote_cell_type":"text-cell-h1"},"source":"# Project 1: Sentiment Analysis","block_group":"0801f944a3d344368ba618ae4043eb1b"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"810ff23e6a054bc5ae9e9899d13b26fe","deepnote_cell_type":"text-cell-h2"},"source":"## Data Loading","block_group":"77c39668eeeb4f31a4f950964c276126"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500356121,"execution_millis":131,"deepnote_to_be_reexecuted":false,"cell_id":"9864c0d56c234c0cb091b331543157a8","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import wordnet\nfrom nltk.corpus import stopwords\nfrom nltk.metrics.distance import jaro_winkler_similarity\nfrom sklearn.pipeline import Pipeline\nfrom unidecode import unidecode\nimport re\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, accuracy_score,f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom keras.models import Model\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils.data_utils import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import LabelEncoder\n# Download WordNet if you haven't already\nnltk.download('wordnet')\nnltk.download('omw-1.4')\nnltk.download('stopwords')","block_group":"9864c0d56c234c0cb091b331543157a8","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500270332,"execution_millis":297,"deepnote_to_be_reexecuted":false,"cell_id":"1e4dc9f61ae2440fbe8d14b4f697c94c","deepnote_cell_type":"code"},"source":"df = pd.read_csv('/work/Preprocessed/cleaned_data.csv')\ndf = df.rename(columns={'tweet': 'cleaned'})\ndf.head()","block_group":"f1408eff3c6748d585f829ac8c74a746","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":2,"row_count":5,"columns":[{"name":"sentimen","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"negatif","count":2},{"name":"netral","count":2},{"name":"positif","count":1}]}},{"name":"cleaned","dtype":"object","stats":{"unique_count":5,"nan_count":0,"categories":[{"name":"kata prabowo indonesia tidak harga bangsa asing berita ini pasti hoax buat kuasa ya kan rockygerung","count":1},{"name":"batu langka tasbih jokowi hadiah dari habib luthfi harga mercy","count":1},{"name":"3 others","count":3}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"sentimen":"negatif","cleaned":"kata prabowo indonesia tidak harga bangsa asing berita ini pasti hoax buat kuasa ya kan rockygerung","_deepnote_index_column":0},{"sentimen":"netral","cleaned":"batu langka tasbih jokowi hadiah dari habib luthfi harga mercy","_deepnote_index_column":1},{"sentimen":"netral","cleaned":"di era jokowi ekonomi indonesia makin baik indonesia maju jokowi lagi jokowi menang total debat","_deepnote_index_column":2},{"sentimen":"positif","cleaned":"bagi sumatera selatan asi games dampak pd ekonomi langsung prediksi capai triliun indonesia maju jokowi hebat","_deepnote_index_column":3},{"sentimen":"negatif","cleaned":"negara kita ngutang buat bngun infrastruktur yang udah dipake masyarakat terus masyarakat ngeluh karena negara ngutang tiap negara itu pasti ngutang utang bisa bayar kalo negara dapet hasil hasil negara itu ya dari pajak","_deepnote_index_column":4}]},"text/plain":"  sentimen                                            cleaned\n0  negatif  kata prabowo indonesia tidak harga bangsa asin...\n1   netral  batu langka tasbih jokowi hadiah dari habib lu...\n2   netral  di era jokowi ekonomi indonesia makin baik ind...\n3  positif  bagi sumatera selatan asi games dampak pd ekon...\n4  negatif  negara kita ngutang buat bngun infrastruktur y...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentimen</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>negatif</td>\n      <td>kata prabowo indonesia tidak harga bangsa asin...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>netral</td>\n      <td>batu langka tasbih jokowi hadiah dari habib lu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>netral</td>\n      <td>di era jokowi ekonomi indonesia makin baik ind...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>positif</td>\n      <td>bagi sumatera selatan asi games dampak pd ekon...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>negatif</td>\n      <td>negara kita ngutang buat bngun infrastruktur y...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/735e896c-caad-4413-aaa0-f8366e5e6ad5","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4340e5e7fcbf418b9f7e69c793a5e107","deepnote_cell_type":"text-cell-h3"},"source":"### Text Tokenization","block_group":"89df8a97f0e04738b27b02d7658c6d1c"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500270635,"execution_millis":202,"deepnote_to_be_reexecuted":false,"cell_id":"8b92120f42e747f797bd550a183a151c","deepnote_cell_type":"code"},"source":"def tweet_tokenization(text):\n    # Kode untuk melakukan tweet tokenization\n    tokens = nltk.tokenize.TweetTokenizer().tokenize(text)\n    return tokens","block_group":"e885e5e2f25a4ad1989dfe757e5916fe","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500361584,"execution_millis":400,"deepnote_to_be_reexecuted":false,"cell_id":"3dce170a32644b8d9ae9111b57b3c99e","deepnote_cell_type":"code"},"source":"df['tokenization'] = df['cleaned'].apply(lambda x: tweet_tokenization(x))","block_group":"b38858ed87d44ea69c543be18a5bd339","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500369940,"execution_millis":201,"deepnote_to_be_reexecuted":false,"cell_id":"ae0b51f8bf5645e28359e937aa9ed034","deepnote_cell_type":"code"},"source":"df.head()","block_group":"045be277ed6442c695d0b4f478118b28","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":3,"row_count":5,"columns":[{"name":"sentimen","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"negatif","count":2},{"name":"netral","count":2},{"name":"positif","count":1}]}},{"name":"cleaned","dtype":"object","stats":{"unique_count":5,"nan_count":0,"categories":[{"name":"kata prabowo indonesia tidak harga bangsa asing berita ini pasti hoax buat kuasa ya kan rockygerung","count":1},{"name":"batu langka tasbih jokowi hadiah dari habib luthfi harga mercy","count":1},{"name":"3 others","count":3}]}},{"name":"tokenization","dtype":"object","stats":{"unique_count":5,"nan_count":0,"categories":[{"name":"['kata', 'prabowo', 'indonesia', 'tidak', 'harga', 'bangsa', 'asing', 'berita', 'ini', 'pasti', 'hoax', 'buat', 'kuasa', 'ya', 'kan', 'rockygerung']","count":1},{"name":"['batu', 'langka', 'tasbih', 'jokowi', 'hadiah', 'dari', 'habib', 'luthfi', 'harga', 'mercy']","count":1},{"name":"3 others","count":3}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"sentimen":"negatif","cleaned":"kata prabowo indonesia tidak harga bangsa asing berita ini pasti hoax buat kuasa ya kan rockygerung","tokenization":"['kata', 'prabowo', 'indonesia', 'tidak', 'harga', 'bangsa', 'asing', 'berita', 'ini', 'pasti', 'hoax', 'buat', 'kuasa', 'ya', 'kan', 'rockygerung']","_deepnote_index_column":0},{"sentimen":"netral","cleaned":"batu langka tasbih jokowi hadiah dari habib luthfi harga mercy","tokenization":"['batu', 'langka', 'tasbih', 'jokowi', 'hadiah', 'dari', 'habib', 'luthfi', 'harga', 'mercy']","_deepnote_index_column":1},{"sentimen":"netral","cleaned":"di era jokowi ekonomi indonesia makin baik indonesia maju jokowi lagi jokowi menang total debat","tokenization":"['di', 'era', 'jokowi', 'ekonomi', 'indonesia', 'makin', 'baik', 'indonesia', 'maju', 'jokowi', 'lagi', 'jokowi', 'menang', 'total', 'debat']","_deepnote_index_column":2},{"sentimen":"positif","cleaned":"bagi sumatera selatan asi games dampak pd ekonomi langsung prediksi capai triliun indonesia maju jokowi hebat","tokenization":"['bagi', 'sumatera', 'selatan', 'asi', 'games', 'dampak', 'pd', 'ekonomi', 'langsung', 'prediksi', 'capai', 'triliun', 'indonesia', 'maju', 'jokowi', 'hebat']","_deepnote_index_column":3},{"sentimen":"negatif","cleaned":"negara kita ngutang buat bngun infrastruktur yang udah dipake masyarakat terus masyarakat ngeluh karena negara ngutang tiap negara itu pasti ngutang utang bisa bayar kalo negara dapet hasil hasil negara itu ya dari pajak","tokenization":"['negara', 'kita', 'ngutang', 'buat', 'bngun', 'infrastruktur', 'yang', 'udah', 'dipake', 'masyarakat', 'terus', 'masyarakat', 'ngeluh', 'karena', 'negara', 'ngutang', 'tiap', 'negara', 'itu', 'pasti', 'ngutang', 'utang', 'bisa', 'bayar', 'kalo', 'negara', 'dapet', 'hasil', 'hasil', 'negara', 'itu', 'ya', 'dari', 'pajak']","_deepnote_index_column":4}]},"text/plain":"  sentimen                                            cleaned  \\\n0  negatif  kata prabowo indonesia tidak harga bangsa asin...   \n1   netral  batu langka tasbih jokowi hadiah dari habib lu...   \n2   netral  di era jokowi ekonomi indonesia makin baik ind...   \n3  positif  bagi sumatera selatan asi games dampak pd ekon...   \n4  negatif  negara kita ngutang buat bngun infrastruktur y...   \n\n                                        tokenization  \n0  [kata, prabowo, indonesia, tidak, harga, bangs...  \n1  [batu, langka, tasbih, jokowi, hadiah, dari, h...  \n2  [di, era, jokowi, ekonomi, indonesia, makin, b...  \n3  [bagi, sumatera, selatan, asi, games, dampak, ...  \n4  [negara, kita, ngutang, buat, bngun, infrastru...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentimen</th>\n      <th>cleaned</th>\n      <th>tokenization</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>negatif</td>\n      <td>kata prabowo indonesia tidak harga bangsa asin...</td>\n      <td>[kata, prabowo, indonesia, tidak, harga, bangs...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>netral</td>\n      <td>batu langka tasbih jokowi hadiah dari habib lu...</td>\n      <td>[batu, langka, tasbih, jokowi, hadiah, dari, h...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>netral</td>\n      <td>di era jokowi ekonomi indonesia makin baik ind...</td>\n      <td>[di, era, jokowi, ekonomi, indonesia, makin, b...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>positif</td>\n      <td>bagi sumatera selatan asi games dampak pd ekon...</td>\n      <td>[bagi, sumatera, selatan, asi, games, dampak, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>negatif</td>\n      <td>negara kita ngutang buat bngun infrastruktur y...</td>\n      <td>[negara, kita, ngutang, buat, bngun, infrastru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/50f8ee3b-4fa8-473a-852d-1cf686c601b1","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500369972,"execution_millis":301,"deepnote_to_be_reexecuted":false,"cell_id":"1d0189ef4ee14f9f89fbf28600792f94","deepnote_cell_type":"code"},"source":"# Assuming 'df' is your DataFrame and 'sentimen' is the column you want to encode\ny = df['sentimen']\n\n# Initialize the LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the 'sentimen' column\ny_encoded = label_encoder.fit_transform(y)\n\n# Replace the 'sentimen' column in the DataFrame with the encoded values\ny = y_encoded","block_group":"edd44181544a4c3297f856b095ee93fc","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"5c8b02e23a3742e3a66b326240bc27d0","deepnote_cell_type":"text-cell-h3"},"source":"### Text Vectorization","block_group":"c84d08e8d68349e1a2f2d4a7f73ce365"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500369984,"execution_millis":289,"deepnote_to_be_reexecuted":false,"cell_id":"7dd681683dfd44a48c762c1656d92bba","deepnote_cell_type":"code"},"source":"result = {}\nproportion = [10,20,30,40,50]\nno = 1","block_group":"49d4c0862ac84cc1b4287f66f933c769","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9fd186aa6b0943feb888d9ef99f89df5","deepnote_cell_type":"text-cell-h3"},"source":"### Count Vectorization","block_group":"edb17cb80cef41e88b47286ab7675208"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d1385208245e40b0b7a9f4fff0516fc4","deepnote_cell_type":"text-cell-p"},"source":"Unigram","block_group":"004a20063279446d97da30f552cb9331"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500369994,"execution_millis":9367,"deepnote_to_be_reexecuted":false,"cell_id":"5d9477bf07804c518be0d3e41cd8cbe4","deepnote_cell_type":"code"},"source":"# Initialize CountVectorizer\nvectorizer = CountVectorizer(ngram_range=(1,1))\n# Fit and transform the tokenized text data\nX = vectorizer.fit_transform(df['cleaned'])\n# Convert the sparse matrix to a DataFrame\nX = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n# Initialize RandomForestClassifier\nrf_classifier = RandomForestClassifier(random_state=42)\n\nfor i in proportion:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i/100, random_state=42)\n    \n    rf_classifier.fit(X_train, y_train)\n    y_pred = rf_classifier.predict(X_test)\n\n    f1 = f1_score(y_test, y_pred, average='macro')\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='macro')\n    recall = recall_score(y_test, y_pred,average='macro')\n\n    result[no] = {\n        \"vectorization\": \"Count Vectorizer\",\n        \"param\": \"unigram\",\n        \"test size\": i,\n        \"f1\": round(f1, 2),\n        \"accuracy\": round(accuracy, 2),\n    }\n    no+=1\n","block_group":"ad196895e13943e99a1ac64082636a87","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"82b8b5dde1914b3eb8e7b10fe9ccd821","deepnote_cell_type":"text-cell-p"},"source":"Unigram-Bigram","block_group":"84a2f9ca290f48e992bff121ad149853"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500379401,"execution_millis":54627,"deepnote_to_be_reexecuted":false,"cell_id":"d5ff0054d28d41b590ab36e53c8b7782","deepnote_cell_type":"code"},"source":"# Initialize CountVectorizer\nvectorizer = CountVectorizer(ngram_range=(1,2))\n# Fit and transform the tokenized text data\nX = vectorizer.fit_transform(df['cleaned'])\n# Convert the sparse matrix to a DataFrame\nX = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n# Initialize RandomForestClassifier\nrf_classifier = RandomForestClassifier(random_state=42)\n\nfor i in proportion:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i/100, random_state=42)\n    \n    rf_classifier.fit(X_train, y_train)\n    y_pred = rf_classifier.predict(X_test)\n\n    f1 = f1_score(y_test, y_pred, average='macro')\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='macro')\n    recall = recall_score(y_test, y_pred,average='macro')\n\n    result[no] = {\n        \"vectorization\": \"Count Vectorizer\",\n        \"param\": \"unigram - bigram\",\n        \"test size\": i,\n        \"f1\": round(f1, 2),\n        \"accuracy\": round(accuracy, 2),\n    }\n    no+=1\n","block_group":"c705fc6a8c574f85a0277c92a4638e96","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9a02de9e672a4596803b577fe19605f6","deepnote_cell_type":"text-cell-p"},"source":"Bigram","block_group":"243c9ca17e474f468455b39d3d1d98d2"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500434072,"execution_millis":95891,"deepnote_to_be_reexecuted":false,"cell_id":"ba4900e0ff3b488a92c537d59e8e1d8c","deepnote_cell_type":"code"},"source":"# Initialize CountVectorizer\nvectorizer = CountVectorizer(ngram_range=(2,2))\n# Fit and transform the tokenized text data\nX = vectorizer.fit_transform(df['cleaned'])\n# Convert the sparse matrix to a DataFrame\nX = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n# Initialize RandomForestClassifier\nrf_classifier = RandomForestClassifier(random_state=42)\n\nfor i in proportion:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i/100, random_state=42)\n    \n    rf_classifier.fit(X_train, y_train)\n    y_pred = rf_classifier.predict(X_test)\n\n    f1 = f1_score(y_test, y_pred, average='macro')\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='macro')\n    recall = recall_score(y_test, y_pred,average='macro')\n\n    result[no] = {\n        \"vectorization\": \"Count Vectorizer\",\n        \"param\": \"bigram\",\n        \"test size\": i,\n        \"f1\": round(f1, 2),\n        \"accuracy\": round(accuracy, 2),\n    }\n    no+=1\n","block_group":"9a6c308c72c44d51957f6536972f52da","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0387ced9b0f945ffbabcb213b10dc65c","deepnote_cell_type":"text-cell-p"},"source":"Trigram","block_group":"4cd89369471e4532b9b844e53dc707c6"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500530000,"execution_millis":156986,"deepnote_to_be_reexecuted":false,"cell_id":"c30d64a57a68406dbfd639817f649e77","deepnote_cell_type":"code"},"source":"# Initialize CountVectorizer\nvectorizer = CountVectorizer(ngram_range=(3,3))\n# Fit and transform the tokenized text data\nX = vectorizer.fit_transform(df['cleaned'])\n# Convert the sparse matrix to a DataFrame\nX = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n# Initialize RandomForestClassifier\nrf_classifier = RandomForestClassifier(random_state=42)\n\nfor i in proportion:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i/100, random_state=42)\n    \n    rf_classifier.fit(X_train, y_train)\n    y_pred = rf_classifier.predict(X_test)\n\n    f1 = f1_score(y_test, y_pred, average='macro')\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='macro')\n    recall = recall_score(y_test, y_pred,average='macro')\n\n    result[no] = {\n        \"vectorization\": \"Count Vectorizer\",\n        \"param\": \"trigram\",\n        \"test size\": i,\n        \"f1\": round(f1, 2),\n        \"accuracy\": round(accuracy, 2),\n    }\n    no+=1\n","block_group":"f4a39cd17e6d4897b906a451bbcee75f","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9e0c3164c8d74ec78b4eddc847b08781","deepnote_cell_type":"text-cell-h3"},"source":"### TF-IDF","block_group":"4b93d586874e4f62a55140e5b68e46d4"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"24c5717c927544cc97fffcfbedd372a8","deepnote_cell_type":"text-cell-p"},"source":"Unigram","block_group":"547e18d749ff40d7941dc5ecf514e53f"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500687024,"execution_millis":9075,"deepnote_to_be_reexecuted":false,"cell_id":"2c6d5711c4b24c66a332eb66fece82e5","deepnote_cell_type":"code"},"source":"# menggunakan data lebih banyak\nvectorizer = TfidfVectorizer(ngram_range=(1,1))\ntfidf = vectorizer.fit_transform(df['cleaned'])\ntfidf_array = tfidf.toarray()\nX = pd.DataFrame(data=tfidf_array, columns = vectorizer.get_feature_names_out()) # untuk scikit learn baru, menggunakan get_feature_names()\n# Initialize RandomForestClassifier\nrf_classifier = RandomForestClassifier(random_state=42)\n\nfor i in proportion:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i/100, random_state=42)\n    \n    rf_classifier.fit(X_train, y_train)\n    y_pred = rf_classifier.predict(X_test)\n\n    f1 = f1_score(y_test, y_pred, average='macro')\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='macro')\n    recall = recall_score(y_test, y_pred,average='macro')\n\n    result[no] = {\n        \"vectorization\": \"TF-IDF\",\n        \"param\": \"Unigram\",\n        \"test size\": i,\n        \"f1\": round(f1, 2),\n        \"accuracy\": round(accuracy, 2),\n    }\n    no+=1\n","block_group":"510129aa88654cc4b9f67ec01105e752","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"ec0ce35dc876407bb02370bd153c4cb7","deepnote_cell_type":"text-cell-p"},"source":"Unigram - Bigram","block_group":"d74f6dec03f647b4b0e23fa79e8222f8"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500696159,"execution_millis":52022,"deepnote_to_be_reexecuted":false,"cell_id":"12466b3e388749e5992a060a146906eb","deepnote_cell_type":"code"},"source":"# menggunakan data lebih banyak\nvectorizer = TfidfVectorizer(ngram_range=(1,2))\ntfidf = vectorizer.fit_transform(df['cleaned'])\ntfidf_array = tfidf.toarray()\nX = pd.DataFrame(data=tfidf_array, columns = vectorizer.get_feature_names_out()) # untuk scikit learn baru, menggunakan get_feature_names()\n# Initialize RandomForestClassifier\nrf_classifier = RandomForestClassifier(random_state=42)\n\nfor i in proportion:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i/100, random_state=42)\n    \n    rf_classifier.fit(X_train, y_train)\n    y_pred = rf_classifier.predict(X_test)\n\n    f1 = f1_score(y_test, y_pred, average='macro')\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='macro')\n    recall = recall_score(y_test, y_pred,average='macro')\n\n    result[no] = {\n        \"vectorization\": \"TF-IDF\",\n        \"param\": \"Unigram - Bigram\",\n        \"test size\": i,\n        \"f1\": round(f1, 2),\n        \"accuracy\": round(accuracy, 2),\n    }\n    no+=1\n","block_group":"345f440f129d48648b16d3aa663ccc1a","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"960ba34bb20b4878bc75e8b5fffd95d5","deepnote_cell_type":"text-cell-p"},"source":"Bigram","block_group":"d88d0c5a11c44d60bbe9a5ef9341a21e"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500748248,"execution_millis":87458,"deepnote_to_be_reexecuted":false,"cell_id":"ba9f105ea6dd44d788cabefaab6866bb","deepnote_cell_type":"code"},"source":"# menggunakan data lebih banyak\nvectorizer = TfidfVectorizer(ngram_range=(2,2))\ntfidf = vectorizer.fit_transform(df['cleaned'])\ntfidf_array = tfidf.toarray()\nX = pd.DataFrame(data=tfidf_array, columns = vectorizer.get_feature_names_out()) # untuk scikit learn baru, menggunakan get_feature_names()\n# Initialize RandomForestClassifier\nrf_classifier = RandomForestClassifier(random_state=42)\n\nfor i in proportion:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i/100, random_state=42)\n    \n    rf_classifier.fit(X_train, y_train)\n    y_pred = rf_classifier.predict(X_test)\n\n    f1 = f1_score(y_test, y_pred, average='macro')\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='macro')\n    recall = recall_score(y_test, y_pred,average='macro')\n\n    result[no] = {\n        \"vectorization\": \"TF-IDF\",\n        \"param\": \"Bigram\",\n        \"test size\": i,\n        \"f1\": round(f1, 2),\n        \"accuracy\": round(accuracy, 2),\n    }\n    no+=1\n\n","block_group":"18ceb514b4804f6691ff250966c656de","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9bccbd235a974c60ba44e5429543fc38","deepnote_cell_type":"text-cell-p"},"source":"Trigram","block_group":"6653ee0b96924c74bdb5eba78509a1ef"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710500835748,"execution_millis":173538,"deepnote_to_be_reexecuted":false,"cell_id":"e38faf666c0141de98228d8ae83b40fc","deepnote_cell_type":"code"},"source":"# menggunakan data lebih banyak\nvectorizer = TfidfVectorizer(ngram_range=(3,3))\ntfidf = vectorizer.fit_transform(df['cleaned'])\ntfidf_array = tfidf.toarray()\nX = pd.DataFrame(data=tfidf_array, columns = vectorizer.get_feature_names_out()) # untuk scikit learn baru, menggunakan get_feature_names()\n# Initialize RandomForestClassifier\nrf_classifier = RandomForestClassifier(random_state=42)\n\nfor i in proportion:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i/100, random_state=42)\n    \n    rf_classifier.fit(X_train, y_train)\n    y_pred = rf_classifier.predict(X_test)\n\n    f1 = f1_score(y_test, y_pred, average='macro')\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='macro')\n    recall = recall_score(y_test, y_pred,average='macro')\n\n    result[no] = {\n        \"vectorization\": \"TF-IDF\",\n        \"param\": \"Bigram\",\n        \"test size\": i,\n        \"f1\": round(f1, 2),\n        \"accuracy\": round(accuracy, 2),\n    }\n    no+=1\n","block_group":"179d033daef34a73a70cfe9a5a50c7f4","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710501009331,"execution_millis":6006,"deepnote_to_be_reexecuted":false,"cell_id":"c9a216616d394fd299f047443cb473b0","deepnote_cell_type":"code"},"source":"!pip install gensim==4.3.2","block_group":"4e41b65f0e194e2597a952c5ca31843e","execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim==4.3.2 in /root/venv/lib/python3.9/site-packages (4.3.2)\nRequirement already satisfied: smart-open>=1.8.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from gensim==4.3.2) (5.2.1)\nRequirement already satisfied: scipy>=1.7.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from gensim==4.3.2) (1.9.3)\nRequirement already satisfied: numpy>=1.18.5 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from gensim==4.3.2) (1.23.4)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/4eb2099b-526d-48da-bc65-643e41f08c44","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710501015346,"execution_millis":92,"deepnote_to_be_reexecuted":false,"cell_id":"3ee3108ece914bb79890b409a37d3cbd","deepnote_cell_type":"code"},"source":"from gensim.models import Word2Vec","block_group":"7722e1308a7f430a9290b9244fc17aa7","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710501015446,"execution_millis":50337,"deepnote_to_be_reexecuted":false,"cell_id":"a39196033fcf4c5d8abc169577e3a107","deepnote_cell_type":"code"},"source":"X = df[\"tokenization\"]\nfor i in range(1,6):\n    for j in proportion:\n        # Train a skip-gram Word2Vec model\n        model = Word2Vec(sentences=X, vector_size=100, window=i, sg=0)\n\n        # Function to get document embeddings\n        def get_doc_embedding(doc):\n            embeddings = [model.wv[word] for word in doc if word in model.wv]\n            if embeddings:\n                return np.mean(embeddings, axis=0)\n            return np.zeros(100)  # Return zero vector if no embeddings found\n\n        # Create document embeddings\n        doc_embeddings = np.array([get_doc_embedding(doc) for doc in X])\n\n        # Split the data into training and test sets\n        X_train, X_test, y_train, y_test = train_test_split(doc_embeddings, y, test_size=j/100, random_state=42)\n\n        # Train a Random Forest classifier\n        rf = RandomForestClassifier(random_state=42)\n        rf.fit(X_train, y_train)\n\n        # Make predictions on the test set\n        y_pred = rf.predict(X_test)\n        f1 = f1_score(y_test, y_pred, average='macro')\n        accuracy = accuracy_score(y_test, y_pred)\n        precision = precision_score(y_test, y_pred, average='macro')\n        recall = recall_score(y_test, y_pred,average='macro')\n\n        result[no] = {\n            \"vectorization\": \"CBOW\",\n            \"param\": \"window {}\".format(i),\n            \"test size\": j,\n            \"f1\": round(f1, 2),\n            \"accuracy\": round(accuracy, 2),\n        }\n        no+=1","block_group":"8052dee04b4d4c5e9cd3f6dc349f1537","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710501065832,"execution_millis":58994,"deepnote_to_be_reexecuted":false,"cell_id":"d187363d3664492eb094ad1edec1cd78","deepnote_cell_type":"code"},"source":"X = df[\"tokenization\"]\nfor i in range(1,6):\n    for j in proportion:\n        # Train a skip-gram Word2Vec model\n        model = Word2Vec(sentences=X, vector_size=100, window=i, sg=1)\n\n        # Function to get document embeddings\n        def get_doc_embedding(doc):\n            embeddings = [model.wv[word] for word in doc if word in model.wv]\n            if embeddings:\n                return np.mean(embeddings, axis=0)\n            return np.zeros(100)  # Return zero vector if no embeddings found\n\n        # Create document embeddings\n        doc_embeddings = np.array([get_doc_embedding(doc) for doc in X])\n\n        # Split the data into training and test sets\n        X_train, X_test, y_train, y_test = train_test_split(doc_embeddings, y, test_size=j/100, random_state=42)\n\n        # Train a Random Forest classifier\n        rf = RandomForestClassifier(random_state=42)\n        rf.fit(X_train, y_train)\n\n        # Make predictions on the test set\n        y_pred = rf.predict(X_test)\n        f1 = f1_score(y_test, y_pred, average='macro')\n        accuracy = accuracy_score(y_test, y_pred)\n        precision = precision_score(y_test, y_pred, average='macro')\n        recall = recall_score(y_test, y_pred,average='macro')\n\n        result[no] = {\n            \"vectorization\": \"CBOW\",\n            \"param\": \"window {}\".format(i),\n            \"test size\": j,\n            \"f1\": round(f1, 2),\n            \"accuracy\": round(accuracy, 2),\n        }\n        no+=1","block_group":"e24139af357144f18123067857f08c6a","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710501124829,"execution_millis":219,"deepnote_to_be_reexecuted":false,"cell_id":"ad0b878aee9d4001af0e3b47dbef84e1","deepnote_cell_type":"code"},"source":"result_lstm = {}","block_group":"975cb19148fd4a778a1e320c7ba0ba47","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710501124830,"execution_millis":218,"deepnote_to_be_reexecuted":false,"cell_id":"8605779da29f48bc86c3af85e151ff5a","deepnote_cell_type":"code"},"source":"sentiment = pd.get_dummies(df[\"sentimen\"])\ndf_baru = pd.concat([df, sentiment], axis=1)\ndf_baru = df_baru.drop(columns=\"sentimen\")\ndf_baru.head()","block_group":"cade9cd4c3f64322aa405756e53da8d7","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":5,"row_count":5,"columns":[{"name":"cleaned","dtype":"object","stats":{"unique_count":5,"nan_count":0,"categories":[{"name":"kata prabowo indonesia tidak harga bangsa asing berita ini pasti hoax buat kuasa ya kan rockygerung","count":1},{"name":"batu langka tasbih jokowi hadiah dari habib luthfi harga mercy","count":1},{"name":"3 others","count":3}]}},{"name":"tokenization","dtype":"object","stats":{"unique_count":5,"nan_count":0,"categories":[{"name":"['kata', 'prabowo', 'indonesia', 'tidak', 'harga', 'bangsa', 'asing', 'berita', 'ini', 'pasti', 'hoax', 'buat', 'kuasa', 'ya', 'kan', 'rockygerung']","count":1},{"name":"['batu', 'langka', 'tasbih', 'jokowi', 'hadiah', 'dari', 'habib', 'luthfi', 'harga', 'mercy']","count":1},{"name":"3 others","count":3}]}},{"name":"negatif","dtype":"bool","stats":{"unique_count":2,"nan_count":0,"categories":[{"name":"False","count":3},{"name":"True","count":2}]}},{"name":"netral","dtype":"bool","stats":{"unique_count":2,"nan_count":0,"categories":[{"name":"False","count":3},{"name":"True","count":2}]}},{"name":"positif","dtype":"bool","stats":{"unique_count":2,"nan_count":0,"categories":[{"name":"False","count":4},{"name":"True","count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"cleaned":"kata prabowo indonesia tidak harga bangsa asing berita ini pasti hoax buat kuasa ya kan rockygerung","tokenization":"['kata', 'prabowo', 'indonesia', 'tidak', 'harga', 'bangsa', 'asing', 'berita', 'ini', 'pasti', 'hoax', 'buat', 'kuasa', 'ya', 'kan', 'rockygerung']","negatif":"True","netral":"False","positif":"False","_deepnote_index_column":0},{"cleaned":"batu langka tasbih jokowi hadiah dari habib luthfi harga mercy","tokenization":"['batu', 'langka', 'tasbih', 'jokowi', 'hadiah', 'dari', 'habib', 'luthfi', 'harga', 'mercy']","negatif":"False","netral":"True","positif":"False","_deepnote_index_column":1},{"cleaned":"di era jokowi ekonomi indonesia makin baik indonesia maju jokowi lagi jokowi menang total debat","tokenization":"['di', 'era', 'jokowi', 'ekonomi', 'indonesia', 'makin', 'baik', 'indonesia', 'maju', 'jokowi', 'lagi', 'jokowi', 'menang', 'total', 'debat']","negatif":"False","netral":"True","positif":"False","_deepnote_index_column":2},{"cleaned":"bagi sumatera selatan asi games dampak pd ekonomi langsung prediksi capai triliun indonesia maju jokowi hebat","tokenization":"['bagi', 'sumatera', 'selatan', 'asi', 'games', 'dampak', 'pd', 'ekonomi', 'langsung', 'prediksi', 'capai', 'triliun', 'indonesia', 'maju', 'jokowi', 'hebat']","negatif":"False","netral":"False","positif":"True","_deepnote_index_column":3},{"cleaned":"negara kita ngutang buat bngun infrastruktur yang udah dipake masyarakat terus masyarakat ngeluh karena negara ngutang tiap negara itu pasti ngutang utang bisa bayar kalo negara dapet hasil hasil negara itu ya dari pajak","tokenization":"['negara', 'kita', 'ngutang', 'buat', 'bngun', 'infrastruktur', 'yang', 'udah', 'dipake', 'masyarakat', 'terus', 'masyarakat', 'ngeluh', 'karena', 'negara', 'ngutang', 'tiap', 'negara', 'itu', 'pasti', 'ngutang', 'utang', 'bisa', 'bayar', 'kalo', 'negara', 'dapet', 'hasil', 'hasil', 'negara', 'itu', 'ya', 'dari', 'pajak']","negatif":"True","netral":"False","positif":"False","_deepnote_index_column":4}]},"text/plain":"                                             cleaned  \\\n0  kata prabowo indonesia tidak harga bangsa asin...   \n1  batu langka tasbih jokowi hadiah dari habib lu...   \n2  di era jokowi ekonomi indonesia makin baik ind...   \n3  bagi sumatera selatan asi games dampak pd ekon...   \n4  negara kita ngutang buat bngun infrastruktur y...   \n\n                                        tokenization  negatif  netral  positif  \n0  [kata, prabowo, indonesia, tidak, harga, bangs...     True   False    False  \n1  [batu, langka, tasbih, jokowi, hadiah, dari, h...    False    True    False  \n2  [di, era, jokowi, ekonomi, indonesia, makin, b...    False    True    False  \n3  [bagi, sumatera, selatan, asi, games, dampak, ...    False   False     True  \n4  [negara, kita, ngutang, buat, bngun, infrastru...     True   False    False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cleaned</th>\n      <th>tokenization</th>\n      <th>negatif</th>\n      <th>netral</th>\n      <th>positif</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kata prabowo indonesia tidak harga bangsa asin...</td>\n      <td>[kata, prabowo, indonesia, tidak, harga, bangs...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>batu langka tasbih jokowi hadiah dari habib lu...</td>\n      <td>[batu, langka, tasbih, jokowi, hadiah, dari, h...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>di era jokowi ekonomi indonesia makin baik ind...</td>\n      <td>[di, era, jokowi, ekonomi, indonesia, makin, b...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bagi sumatera selatan asi games dampak pd ekon...</td>\n      <td>[bagi, sumatera, selatan, asi, games, dampak, ...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>negara kita ngutang buat bngun infrastruktur y...</td>\n      <td>[negara, kita, ngutang, buat, bngun, infrastru...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/3b390496-fb08-4e37-b883-28c858b51ed3","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b34f4431247246c8a1783256c041e4fd","deepnote_cell_type":"text-cell-h3"},"source":"### LSTM","block_group":"a60ea383d00f4d7191dc0a4eef602654"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710501965744,"execution_millis":84,"deepnote_to_be_reexecuted":false,"cell_id":"e24063108bfc4483ac3865dfcb714d4b","deepnote_cell_type":"code"},"source":"def RNN():\n    inputs = Input(name='inputs', shape=(X.shape[1],))\n    layer = Embedding(input_dim=1000, output_dim=50, input_length=X.shape[1])(inputs)\n    layer = LSTM(64)(layer)\n    layer = Dense(256, name='FC1')(layer)\n    layer = Activation('relu')(layer)\n    layer = Dropout(0.5)(layer)\n    layer = Dense(3, name='out_layer')(layer)\n    layer = Activation('softmax')(layer)\n    model = Model(inputs=inputs, outputs=layer)\n    return model","block_group":"76d4f6550d4c42cfbea81aaeeaa34a0b","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710502817189,"execution_millis":34975,"deepnote_to_be_reexecuted":false,"cell_id":"fd2e4f5fda63430296f384487f07da88","deepnote_cell_type":"code"},"source":"no = 1\nfor tipe in range(0,2):\n    for window in range(2,4):\n        print('-'*100)\n        print(vectorization)\n        print(\"Window {}\".format(window))\n        print('-'*100)\n        # Train a skip-gram Word2Vec model\n        model = Word2Vec(sentences=df_baru[\"tokenization\"], vector_size=100, window=2, sg=tipe)\n\n        # Function to get document embeddings\n        def get_doc_embedding(doc):\n            embeddings = [model.wv[word] for word in doc if word in model.wv]\n            if embeddings:\n                return np.mean(embeddings, axis=0)\n            return np.zeros(100)  # Return zero vector if no embeddings found\n\n        # Create document embeddings\n        doc_embeddings = np.array([get_doc_embedding(doc) for doc in X])\n        y = df_baru[['negatif', 'netral', 'positif']].values\n        max_length = max(len(seq) for seq in doc_embeddings)\n        padded_sequences = pad_sequences(doc_embeddings, maxlen=max_length, padding='post', dtype='float32')\n        # Assuming y_train is your labels\n        X = np.array(padded_sequences)\n        y = np.array(y)\n        # Split the data into training and test sets\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n        model_rnn = RNN()\n        model_rnn.compile(loss='categorical_crossentropy', optimizer=RMSprop(),metrics=['accuracy'])\n\n        # Train the RNN model\n        history = model_rnn.fit(X_train, y_train, batch_size=128, epochs=10, verbose=2,validation_split=0.2, \n        callbacks=[EarlyStopping(monitor='val_loss', min_delta=0.0001)])\n        loss, accuracy = model_rnn.evaluate(X_test, y_test)\n        # Predict labels for test data\n        y_pred = model_rnn.predict(X_test)\n\n        # Convert predicted probabilities to class labels\n        y_pred_classes = np.argmax(y_pred, axis=1)\n\n        # Convert one-hot encoded labels to single labels\n        y_true = np.argmax(y_test, axis=1)\n\n        # Calculate F1 score\n        f1 = f1_score(y_true, y_pred_classes, average='weighted')\n        if tipe == 0:\n            vectorization = \"CBOW\"\n        else:\n            vectorization = \"Skip Gram\"\n\n        result_lstm[no] = {\n            \"vectorization\": vectorization,\n            \"param\": \"window {}\".format(window),\n            \"f1\": round(f1, 2),\n            \"accuracy\": round(accuracy, 2),\n        }\n        no+=1\n        ","block_group":"65ee2b577c444f259c04fcf1ab09dd77","execution_count":null,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------------------------------------------\nSkip Gram\nWindow 2\n----------------------------------------------------------------------------------------------------\nEpoch 1/10\n10/10 - 5s - loss: 1.1001 - accuracy: 0.3170 - val_loss: 1.0998 - val_accuracy: 0.2955 - 5s/epoch - 453ms/step\nEpoch 2/10\n10/10 - 2s - loss: 1.0990 - accuracy: 0.3187 - val_loss: 1.1016 - val_accuracy: 0.2955 - 2s/epoch - 209ms/step\n12/12 [==============================] - 0s 27ms/step - loss: 1.0976 - accuracy: 0.3581\n12/12 [==============================] - 1s 22ms/step\n----------------------------------------------------------------------------------------------------\nCBOW\nWindow 3\n----------------------------------------------------------------------------------------------------\nEpoch 1/10\n10/10 - 5s - loss: 1.0998 - accuracy: 0.3161 - val_loss: 1.0994 - val_accuracy: 0.3505 - 5s/epoch - 514ms/step\nEpoch 2/10\n10/10 - 2s - loss: 1.0997 - accuracy: 0.3213 - val_loss: 1.0983 - val_accuracy: 0.3540 - 2s/epoch - 201ms/step\n12/12 [==============================] - 0s 26ms/step - loss: 1.0988 - accuracy: 0.3251\n12/12 [==============================] - 1s 25ms/step\n----------------------------------------------------------------------------------------------------\nCBOW\nWindow 2\n----------------------------------------------------------------------------------------------------\nEpoch 1/10\n10/10 - 5s - loss: 1.1002 - accuracy: 0.3144 - val_loss: 1.0999 - val_accuracy: 0.2955 - 5s/epoch - 459ms/step\nEpoch 2/10\n10/10 - 2s - loss: 1.0992 - accuracy: 0.3385 - val_loss: 1.1006 - val_accuracy: 0.2955 - 2s/epoch - 209ms/step\n12/12 [==============================] - 0s 25ms/step - loss: 1.0978 - accuracy: 0.3581\n12/12 [==============================] - 1s 24ms/step\n----------------------------------------------------------------------------------------------------\nSkip Gram\nWindow 3\n----------------------------------------------------------------------------------------------------\nEpoch 1/10\n10/10 - 5s - loss: 1.0990 - accuracy: 0.3402 - val_loss: 1.0997 - val_accuracy: 0.3540 - 5s/epoch - 452ms/step\nEpoch 2/10\n10/10 - 2s - loss: 1.0998 - accuracy: 0.3187 - val_loss: 1.1015 - val_accuracy: 0.2955 - 2s/epoch - 208ms/step\n12/12 [==============================] - 0s 25ms/step - loss: 1.0974 - accuracy: 0.3581\n12/12 [==============================] - 1s 24ms/step\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/604aecb1-d6d4-44fc-a4df-f5bd16806b49","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710502873950,"execution_millis":52996,"deepnote_to_be_reexecuted":false,"cell_id":"8207efd84a5d4e7d80a8860df4a7d160","deepnote_cell_type":"code"},"source":"types = [(CountVectorizer(ngram_range=(1,1)), \"unigram\", \"Count Vectorizer\"), \n(CountVectorizer(ngram_range=(1,2)), \"unigram - Bigram\", \"Count Vectorizer\"),\n(CountVectorizer(ngram_range=(2,2)), \"Bigram\", \"Count Vectorizer\"),\n(CountVectorizer(ngram_range=(3,3)), \"Trigram\", \"Count Vectorizer\"),\n(TfidfVectorizer(ngram_range=(1,1)), \"unigram\", \"TF-IDF\"),\n(TfidfVectorizer(ngram_range=(1,2)), \"unigram - Bigram\", \"TF-IDF\"),\n(TfidfVectorizer(ngram_range=(3,3)), \"Trigram\", \"TF-IDF\")]\nfor tipe in types:\n    print('-'*100)\n    print(tipe[2])\n    print(\"Ngram {}\".format(tipe[1]))\n    print('-'*100)\n    vectorizer = tipe[0]\n    result_vec = vectorizer.fit_transform(df['cleaned'])\n    X = result_vec.toarray()\n    y = df_baru[['negatif', 'netral', 'positif']].values\n    max_length = max(len(np.nonzero(row)[0]) for row in X)\n    padded_sequences = pad_sequences(X, maxlen=max_length, padding='post', dtype='float32')\n    # Assuming y_train is your labels\n    X = np.array(padded_sequences)\n    y = np.array(y)\n    # Split the data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    model_rnn = RNN()\n    model_rnn.compile(loss='categorical_crossentropy', optimizer=RMSprop(),metrics=['accuracy'])\n\n    # Train the RNN model\n    history = model_rnn.fit(X_train, y_train, batch_size=128, epochs=10, verbose=2,validation_split=0.2, \n    callbacks=[EarlyStopping(monitor='val_loss', min_delta=0.0001)])\n    loss, accuracy = model_rnn.evaluate(X_test, y_test)\n    # Predict labels for test data\n    y_pred = model_rnn.predict(X_test)\n\n    # Convert predicted probabilities to class labels\n    y_pred_classes = np.argmax(y_pred, axis=1)\n\n    # Convert one-hot encoded labels to single labels\n    y_true = np.argmax(y_test, axis=1)\n\n    # Calculate F1 score\n    f1 = f1_score(y_true, y_pred_classes, average='weighted')\n\n    result_lstm[no] = {\n        \"vectorization\": tipe[2],\n        \"param\": \"{}\".format(tipe[1]),\n        \"f1\": round(f1, 2),\n        \"accuracy\": round(accuracy, 2),\n    }\n    no+=1\n        ","block_group":"a11e2b251573417a8c363dc8ed65b335","execution_count":null,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------------------------------------------\nCount Vectorizer\nNgram unigram\n----------------------------------------------------------------------------------------------------\nEpoch 1/10\n10/10 - 3s - loss: 1.1002 - accuracy: 0.3161 - val_loss: 1.1023 - val_accuracy: 0.2955 - 3s/epoch - 333ms/step\nEpoch 2/10\n10/10 - 1s - loss: 1.0998 - accuracy: 0.3376 - val_loss: 1.1009 - val_accuracy: 0.2955 - 984ms/epoch - 98ms/step\n12/12 [==============================] - 0s 14ms/step - loss: 1.0976 - accuracy: 0.3581\n12/12 [==============================] - 0s 9ms/step\n----------------------------------------------------------------------------------------------------\nCount Vectorizer\nNgram unigram - Bigram\n----------------------------------------------------------------------------------------------------\nEpoch 1/10\n10/10 - 4s - loss: 1.0997 - accuracy: 0.3316 - val_loss: 1.0990 - val_accuracy: 0.2955 - 4s/epoch - 433ms/step\nEpoch 2/10\n10/10 - 2s - loss: 1.0998 - accuracy: 0.3325 - val_loss: 1.1039 - val_accuracy: 0.2955 - 2s/epoch - 181ms/step\n12/12 [==============================] - 0s 23ms/step - loss: 1.0972 - accuracy: 0.3581\n12/12 [==============================] - 1s 19ms/step\n----------------------------------------------------------------------------------------------------\nCount Vectorizer\nNgram Bigram\n----------------------------------------------------------------------------------------------------\nEpoch 1/10\n10/10 - 4s - loss: 1.0998 - accuracy: 0.3419 - val_loss: 1.1005 - val_accuracy: 0.2955 - 4s/epoch - 360ms/step\nEpoch 2/10\n10/10 - 1s - loss: 1.0994 - accuracy: 0.3230 - val_loss: 1.0981 - val_accuracy: 0.3505 - 1s/epoch - 110ms/step\n12/12 [==============================] - 0s 12ms/step - loss: 1.0993 - accuracy: 0.3168\n12/12 [==============================] - 1s 14ms/step\n----------------------------------------------------------------------------------------------------\nCount Vectorizer\nNgram Trigram\n----------------------------------------------------------------------------------------------------\nEpoch 1/10\n10/10 - 3s - loss: 1.1004 - accuracy: 0.3247 - val_loss: 1.1017 - val_accuracy: 0.2955 - 3s/epoch - 338ms/step\nEpoch 2/10\n10/10 - 1s - loss: 1.0999 - accuracy: 0.3394 - val_loss: 1.1016 - val_accuracy: 0.2955 - 1s/epoch - 103ms/step\n12/12 [==============================] - 0s 15ms/step - loss: 1.0974 - accuracy: 0.3581\n12/12 [==============================] - 1s 10ms/step\n----------------------------------------------------------------------------------------------------\nTF-IDF\nNgram unigram\n----------------------------------------------------------------------------------------------------\nEpoch 1/10\n10/10 - 3s - loss: 1.0994 - accuracy: 0.3239 - val_loss: 1.1027 - val_accuracy: 0.2955 - 3s/epoch - 329ms/step\nEpoch 2/10\n10/10 - 1s - loss: 1.0996 - accuracy: 0.3247 - val_loss: 1.0991 - val_accuracy: 0.3540 - 999ms/epoch - 100ms/step\n12/12 [==============================] - 0s 8ms/step - loss: 1.0988 - accuracy: 0.3251\n12/12 [==============================] - 0s 13ms/step\n----------------------------------------------------------------------------------------------------\nTF-IDF\nNgram unigram - Bigram\n----------------------------------------------------------------------------------------------------\nEpoch 1/10\n10/10 - 5s - loss: 1.1004 - accuracy: 0.3368 - val_loss: 1.1010 - val_accuracy: 0.2955 - 5s/epoch - 505ms/step\nEpoch 2/10\n10/10 - 2s - loss: 1.0994 - accuracy: 0.3118 - val_loss: 1.0988 - val_accuracy: 0.3540 - 2s/epoch - 190ms/step\n12/12 [==============================] - 0s 24ms/step - loss: 1.0985 - accuracy: 0.3251\n12/12 [==============================] - 1s 17ms/step\n----------------------------------------------------------------------------------------------------\nTF-IDF\nNgram Trigram\n----------------------------------------------------------------------------------------------------\nEpoch 1/10\n10/10 - 5s - loss: 1.1010 - accuracy: 0.3170 - val_loss: 1.0986 - val_accuracy: 0.3505 - 5s/epoch - 507ms/step\nEpoch 2/10\n10/10 - 2s - loss: 1.0989 - accuracy: 0.3256 - val_loss: 1.0984 - val_accuracy: 0.3540 - 2s/epoch - 180ms/step\n12/12 [==============================] - 0s 12ms/step - loss: 1.0987 - accuracy: 0.3251\n12/12 [==============================] - 1s 12ms/step\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/ab9c2b97-be3a-475c-aea1-78d76beded82","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710503538782,"execution_millis":257,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":10,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"cell_id":"93f5424a99c94bc1ab6a660e47f5643b","deepnote_cell_type":"code"},"source":"lstm_result_df = pd.DataFrame(result_lstm).transpose()\nlstm_result_df.reset_index(drop=True,inplace=True)\nlstm_result_df","block_group":"a5b6084cdddf4f85bbf043ea64892191","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":4,"row_count":18,"columns":[{"name":"vectorization","dtype":"object","stats":{"unique_count":4,"nan_count":0,"categories":[{"name":"Count Vectorizer","count":8},{"name":"TF-IDF","count":6},{"name":"2 others","count":4}]}},{"name":"param","dtype":"object","stats":{"unique_count":8,"nan_count":0,"categories":[{"name":"Count Vectorizer","count":4},{"name":"TF-IDF","count":3},{"name":"6 others","count":11}]}},{"name":"f1","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"0.16","count":8},{"name":"0.19","count":7},{"name":"0.15","count":3}]}},{"name":"accuracy","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"0.33","count":8},{"name":"0.36","count":7},{"name":"0.32","count":3}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"vectorization":"CBOW","param":"window 2","f1":"0.19","accuracy":"0.36","_deepnote_index_column":0},{"vectorization":"CBOW","param":"window 3","f1":"0.16","accuracy":"0.33","_deepnote_index_column":1},{"vectorization":"Skip Gram","param":"window 2","f1":"0.19","accuracy":"0.36","_deepnote_index_column":2},{"vectorization":"Skip Gram","param":"window 3","f1":"0.19","accuracy":"0.36","_deepnote_index_column":3},{"vectorization":"Count Vectorizer","param":"unigram","f1":"0.19","accuracy":"0.36","_deepnote_index_column":4},{"vectorization":"Count Vectorizer","param":"unigram - Bigram","f1":"0.19","accuracy":"0.36","_deepnote_index_column":5},{"vectorization":"Count Vectorizer","param":"Bigram","f1":"0.15","accuracy":"0.32","_deepnote_index_column":6},{"vectorization":"Count Vectorizer","param":"Trigram","f1":"0.19","accuracy":"0.36","_deepnote_index_column":7},{"vectorization":"TF-IDF","param":"unigram","f1":"0.16","accuracy":"0.33","_deepnote_index_column":8},{"vectorization":"TF-IDF","param":"unigram - Bigram","f1":"0.16","accuracy":"0.33","_deepnote_index_column":9}]},"text/plain":"       vectorization             param    f1 accuracy\n0               CBOW          window 2  0.19     0.36\n1               CBOW          window 3  0.16     0.33\n2          Skip Gram          window 2  0.19     0.36\n3          Skip Gram          window 3  0.19     0.36\n4   Count Vectorizer           unigram  0.19     0.36\n5   Count Vectorizer  unigram - Bigram  0.19     0.36\n6   Count Vectorizer            Bigram  0.15     0.32\n7   Count Vectorizer           Trigram  0.19     0.36\n8             TF-IDF           unigram  0.16     0.33\n9             TF-IDF  unigram - Bigram  0.16     0.33\n10            TF-IDF           Trigram  0.16     0.33\n11  Count Vectorizer  Count Vectorizer  0.16     0.33\n12  Count Vectorizer  Count Vectorizer  0.15     0.32\n13  Count Vectorizer  Count Vectorizer  0.16     0.33\n14  Count Vectorizer  Count Vectorizer  0.16     0.33\n15            TF-IDF            TF-IDF  0.19     0.36\n16            TF-IDF            TF-IDF  0.16     0.33\n17            TF-IDF            TF-IDF  0.15     0.32","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>vectorization</th>\n      <th>param</th>\n      <th>f1</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CBOW</td>\n      <td>window 2</td>\n      <td>0.19</td>\n      <td>0.36</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CBOW</td>\n      <td>window 3</td>\n      <td>0.16</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Skip Gram</td>\n      <td>window 2</td>\n      <td>0.19</td>\n      <td>0.36</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Skip Gram</td>\n      <td>window 3</td>\n      <td>0.19</td>\n      <td>0.36</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Count Vectorizer</td>\n      <td>unigram</td>\n      <td>0.19</td>\n      <td>0.36</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Count Vectorizer</td>\n      <td>unigram - Bigram</td>\n      <td>0.19</td>\n      <td>0.36</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Count Vectorizer</td>\n      <td>Bigram</td>\n      <td>0.15</td>\n      <td>0.32</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Count Vectorizer</td>\n      <td>Trigram</td>\n      <td>0.19</td>\n      <td>0.36</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>TF-IDF</td>\n      <td>unigram</td>\n      <td>0.16</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>TF-IDF</td>\n      <td>unigram - Bigram</td>\n      <td>0.16</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>TF-IDF</td>\n      <td>Trigram</td>\n      <td>0.16</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Count Vectorizer</td>\n      <td>Count Vectorizer</td>\n      <td>0.16</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Count Vectorizer</td>\n      <td>Count Vectorizer</td>\n      <td>0.15</td>\n      <td>0.32</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Count Vectorizer</td>\n      <td>Count Vectorizer</td>\n      <td>0.16</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Count Vectorizer</td>\n      <td>Count Vectorizer</td>\n      <td>0.16</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>TF-IDF</td>\n      <td>TF-IDF</td>\n      <td>0.19</td>\n      <td>0.36</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>TF-IDF</td>\n      <td>TF-IDF</td>\n      <td>0.16</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>TF-IDF</td>\n      <td>TF-IDF</td>\n      <td>0.15</td>\n      <td>0.32</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/a292d7de-ef40-4245-af9b-2a8465c8f5e1","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710503553658,"execution_millis":239,"deepnote_table_state":{"sortBy":[{"id":"accuracy","type":"desc"}],"filters":[],"pageSize":10,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"cell_id":"8d719c421ef7410c89b2747c294c0241","deepnote_cell_type":"code"},"source":"rf_result_df = pd.DataFrame(result).transpose()\nrf_result_df.reset_index(drop=True,inplace=True)\nrf_result_df","block_group":"64a3e46d8b5d401b9e78f7ba4c6c5f31","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":5,"row_count":90,"columns":[{"name":"vectorization","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"CBOW","count":50},{"name":"TF-IDF","count":20},{"name":"Count Vectorizer","count":20}]}},{"name":"param","dtype":"object","stats":{"unique_count":12,"nan_count":0,"categories":[{"name":"window 1","count":10},{"name":"window 5","count":10},{"name":"10 others","count":70}]}},{"name":"test size","dtype":"object","stats":{"unique_count":5,"nan_count":0,"categories":[{"name":"10","count":18},{"name":"20","count":18},{"name":"3 others","count":54}]}},{"name":"f1","dtype":"object","stats":{"unique_count":24,"nan_count":0,"categories":[{"name":"0.54","count":10},{"name":"0.55","count":9},{"name":"22 others","count":71}]}},{"name":"accuracy","dtype":"object","stats":{"unique_count":21,"nan_count":0,"categories":[{"name":"0.55","count":12},{"name":"0.5","count":9},{"name":"19 others","count":69}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"vectorization":"TF-IDF","param":"Unigram - Bigram","test size":"10","f1":"0.66","accuracy":"0.66","_deepnote_index_column":25},{"vectorization":"Count Vectorizer","param":"unigram","test size":"10","f1":"0.61","accuracy":"0.61","_deepnote_index_column":0},{"vectorization":"TF-IDF","param":"Unigram","test size":"20","f1":"0.61","accuracy":"0.61","_deepnote_index_column":21},{"vectorization":"TF-IDF","param":"Unigram - Bigram","test size":"20","f1":"0.61","accuracy":"0.61","_deepnote_index_column":26},{"vectorization":"CBOW","param":"window 1","test size":"10","f1":"0.6","accuracy":"0.6","_deepnote_index_column":65},{"vectorization":"CBOW","param":"window 5","test size":"10","f1":"0.59","accuracy":"0.6","_deepnote_index_column":60},{"vectorization":"CBOW","param":"window 1","test size":"10","f1":"0.59","accuracy":"0.6","_deepnote_index_column":40},{"vectorization":"Count Vectorizer","param":"unigram","test size":"20","f1":"0.59","accuracy":"0.59","_deepnote_index_column":1},{"vectorization":"CBOW","param":"window 2","test size":"10","f1":"0.58","accuracy":"0.59","_deepnote_index_column":45},{"vectorization":"Count Vectorizer","param":"unigram","test size":"30","f1":"0.59","accuracy":"0.59","_deepnote_index_column":2}]},"text/plain":"       vectorization     param test size    f1 accuracy\n0   Count Vectorizer   unigram        10  0.61     0.61\n1   Count Vectorizer   unigram        20  0.59     0.59\n2   Count Vectorizer   unigram        30  0.59     0.59\n3   Count Vectorizer   unigram        40  0.56     0.56\n4   Count Vectorizer   unigram        50  0.54     0.55\n..               ...       ...       ...   ...      ...\n85              CBOW  window 5        10  0.57     0.58\n86              CBOW  window 5        20  0.55     0.55\n87              CBOW  window 5        30  0.55     0.55\n88              CBOW  window 5        40  0.55     0.55\n89              CBOW  window 5        50  0.54     0.54\n\n[90 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>vectorization</th>\n      <th>param</th>\n      <th>test size</th>\n      <th>f1</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Count Vectorizer</td>\n      <td>unigram</td>\n      <td>10</td>\n      <td>0.61</td>\n      <td>0.61</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Count Vectorizer</td>\n      <td>unigram</td>\n      <td>20</td>\n      <td>0.59</td>\n      <td>0.59</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Count Vectorizer</td>\n      <td>unigram</td>\n      <td>30</td>\n      <td>0.59</td>\n      <td>0.59</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Count Vectorizer</td>\n      <td>unigram</td>\n      <td>40</td>\n      <td>0.56</td>\n      <td>0.56</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Count Vectorizer</td>\n      <td>unigram</td>\n      <td>50</td>\n      <td>0.54</td>\n      <td>0.55</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>CBOW</td>\n      <td>window 5</td>\n      <td>10</td>\n      <td>0.57</td>\n      <td>0.58</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>CBOW</td>\n      <td>window 5</td>\n      <td>20</td>\n      <td>0.55</td>\n      <td>0.55</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>CBOW</td>\n      <td>window 5</td>\n      <td>30</td>\n      <td>0.55</td>\n      <td>0.55</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>CBOW</td>\n      <td>window 5</td>\n      <td>40</td>\n      <td>0.55</td>\n      <td>0.55</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>CBOW</td>\n      <td>window 5</td>\n      <td>50</td>\n      <td>0.54</td>\n      <td>0.54</td>\n    </tr>\n  </tbody>\n</table>\n<p>90 rows × 5 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/f30ff352-b075-4347-a29f-d309c6508525","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"1c690ac1c91a45668fc6ba48c5673f8f","deepnote_cell_type":"text-cell-h2"},"source":"## Hyperparameter Tuning","block_group":"2878de5e657d431ea5fad9b376094c5c"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b8b09147f4da42d3b050f0fd4f1056af","deepnote_cell_type":"text-cell-h3"},"source":"### Random Forest","block_group":"3c31a65bc9da4fb2845b4f8010c7bce8"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710503637176,"execution_millis":0,"deepnote_to_be_reexecuted":false,"cell_id":"f017dd1c1c7b4c6f8356e60d0b8b0ef2","deepnote_cell_type":"code"},"source":"from sklearn.model_selection import GridSearchCV\n\n# Define the parameter grid to search\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [10, 20, 30, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['auto', 'sqrt'],\n    'bootstrap': [True, False]\n}\nvectorizer = TfidfVectorizer(ngram_range=(1,2))\ntfidf = vectorizer.fit_transform(df['cleaned'])\ntfidf_array = tfidf.toarray()\nX = pd.DataFrame(data=tfidf_array, columns = vectorizer.get_feature_names_out())\ny = df[\"sentimen\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\n# Create a base model\nrf = RandomForestClassifier()\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n                           cv=3, n_jobs=-1, verbose=2)\n\n# Fit the grid search to the data\ngrid_search.fit(X_train, y_train)\n\n# Get the best parameters\nbest_params = grid_search.best_params_\ny_pred = grid_search.predict(X_test)\n\nf1 = f1_score(y_test, y_pred, average='macro')\naccuracy = accuracy_score(y_test, y_pred)\nresult_after_hyperparameter[\"Random Forest\"] = {\n    \"vectorization\": \"TF-IDF\",\n    \"param\": \"Unigram - Bigram\",\n    \"f1\": round(f1, 2),\n    \"accuracy\": round(accuracy, 2),\n}","block_group":"bf9018a745374a2f992be71cd19466af","execution_count":0,"outputs":[{"name":"stdout","text":"[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  18.0s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.6s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.4s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.6s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  11.9s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  16.7s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  17.7s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  19.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  17.3s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  16.7s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.2s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  11.4s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  11.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  12.3s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  16.9s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  16.7s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  16.4s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.6s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  12.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  11.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  12.7s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  19.2s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  18.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  18.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.8s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   9.5s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.6s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  16.1s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  15.4s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  14.7s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  21.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  21.0s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  21.1s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.9s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.1s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.0s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  14.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  14.7s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  14.3s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  20.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  20.3s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  20.3s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.1s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.0s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.3s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  14.1s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  14.0s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  13.8s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  19.7s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  20.5s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  20.0s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.4s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.4s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  12.3s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  12.6s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  12.8s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  18.4s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  18.0s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  18.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   7.4s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   7.6s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   7.1s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  12.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  12.7s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  12.7s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  20.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  19.7s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  18.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   7.3s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   7.4s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   7.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  12.3s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  12.6s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  12.4s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  17.9s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  17.8s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  17.8s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.6s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.6s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.7s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  11.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  11.4s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  11.8s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  15.9s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  16.8s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  16.5s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.6s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.6s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.7s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  11.0s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  12.3s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  11.9s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  16.0s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  16.3s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  16.8s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.7s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.8s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.8s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  11.2s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  11.6s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  11.7s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  15.9s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  16.5s\n[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  16.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  23.6s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.0s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.3s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  34.2s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  35.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  36.3s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  13.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  13.3s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  21.9s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  23.0s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  23.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  32.2s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  32.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  34.4s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  11.4s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  11.9s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.6s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  24.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  22.0s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  22.7s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  30.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  32.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  32.4s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   9.4s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  10.0s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   9.9s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  16.6s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  18.7s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  18.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  24.7s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  26.2s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  26.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.4s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  10.0s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.9s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  16.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  17.4s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  18.3s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  24.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  30.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  29.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  10.0s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   9.9s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  10.0s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  16.9s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  17.3s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  17.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  24.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  27.7s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  27.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   7.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   7.6s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  13.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  14.3s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  13.9s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  18.9s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  20.0s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  20.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.4s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  13.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  13.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  13.8s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  18.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  19.1s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  20.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.7s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   8.2s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   8.2s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  13.0s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  14.3s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  13.3s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  18.5s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  19.0s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  20.6s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.1s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.0s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.4s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  23.5s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.0s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.5s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  34.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  35.4s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  38.3s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.8s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.3s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.3s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  22.1s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  23.0s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  23.4s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  32.4s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  33.2s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  34.1s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  11.6s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  11.8s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.1s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  21.3s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  22.0s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  22.9s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  30.6s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  31.6s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  32.6s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   9.3s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   9.6s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   9.9s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  16.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  17.4s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  17.9s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  24.4s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  25.0s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  26.1s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.0s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.5s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  16.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  17.2s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  18.2s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  23.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  24.9s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  25.8s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   9.3s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   9.8s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   9.8s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  15.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  17.0s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  17.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  29.5s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  25.5s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  26.3s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.3s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   9.3s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.4s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  14.0s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  13.6s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  13.8s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  19.2s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  19.2s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  19.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.6s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.9s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  12.9s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  13.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  14.0s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  18.9s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  19.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  19.5s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.3s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.7s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.8s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  13.0s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  13.4s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  13.6s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  18.5s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  19.3s\n[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  19.7s\n/root/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n","output_type":"stream"},{"output_type":"error","ename":"NameError","evalue":"name 'result_after_hyperparameter' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [45], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mresult_after_hyperparameter\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF-IDF\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnigram - Bigram\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(f1, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(accuracy, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     41\u001b[0m }\n","\u001b[0;31mNameError\u001b[0m: name 'result_after_hyperparameter' is not defined"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/c7a56d02-d186-4619-b944-00061bb2e427","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c87c8812a3184e3ca418657b3fd576c3","deepnote_cell_type":"text-cell-h3"},"source":"### LSTM","block_group":"174adbf82abe468e9cb50122f8415041"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"5f1ee1e47afb4c0e8bb92d55b0f225ac","deepnote_cell_type":"code"},"source":"def create_model(learning_rate, num_hidden_layers, num_neurons):\n    inputs = Input(name='inputs', shape=(X.shape[1],))\n    layer = Embedding(input_dim=max_words, output_dim=50, input_length=X.shape[1])(inputs)\n    layer = LSTM(64)(layer)\n    for i in range(num_hidden_layers):\n        layer = Dense(num_neurons)(layer)\n        layer = Activation('relu')(layer)\n    layer = Dropout(0.5)(layer)\n    layer = Dense(3, name='out_layer')(layer)\n    layer = Activation('softmax')(layer)\n    model = Model(inputs=inputs, outputs=layer)\n    optimizer = RMSprop(learning_rate=learning_rate)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model","block_group":"ffec1afa13514d82ac1a135c59d9fbfc","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"31eb1f470011469487959d2b6a9dbc15","deepnote_cell_type":"code"},"source":"# Define the objective function to optimize\ndef objective(learning_rate, num_hidden_layers, num_neurons):\n    model = create_model(learning_rate, int(num_hidden_layers), int(num_neurons))\n    model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=0)\n    val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n    return val_acc","block_group":"8959de05c3cb46478c296d5a8415d336","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"29b9fc26e6d146b599357c2b27e5b2b6","deepnote_cell_type":"code"},"source":"# Define the search space for hyperparameters\npbounds = {'learning_rate': (0.0001, 0.1),\n           'num_hidden_layers': (1, 5),\n           'num_neurons': (5, 50)}","block_group":"96ed3d8a20434ff5b55a5de5351862ad","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"a79706f285d04bd0aff4a3fe536e10ae","deepnote_cell_type":"code"},"source":"model = Word2Vec(sentences=df_baru[\"tokenization\"], vector_size=100, window=2, sg=0)\n# Function to get document embeddings\ndef get_doc_embedding(doc):\n    embeddings = [model.wv[word] for word in doc if word in model.wv]\n    if embeddings:\n        return np.mean(embeddings, axis=0)\n    return np.zeros(100)  # Return zero vector if no embeddings found\n\n# Create document embeddings\ndoc_embeddings = np.array([get_doc_embedding(doc) for doc in X])\ny = df_baru[['negatif', 'netral', 'positif']].values\nmax_length = max(len(seq) for seq in doc_embeddings)\npadded_sequences = pad_sequences(doc_embeddings, maxlen=max_length, padding='post', dtype='float32')\n# Assuming y_train is your labels\nX = np.array(padded_sequences)\ny = np.array(y)\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Perform Bayesian optimization\noptimizer = BayesianOptimization(f=objective, pbounds=pbounds, verbose=2)\noptimizer.maximize(init_points=5, n_iter=20)","block_group":"74c577dc56e544098aa1fdbc4e0ad4e7","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"1a8aae248d2440f7a8cc5e2253d2bbe9","deepnote_cell_type":"code"},"source":"# Print the optimized hyperparameters and validation accuracy\nprint('Optimized hyperparameters:')\nprint(optimizer.max['params'])\nprint('Validation accuracy: {:.2f}%'.format(optimizer.max['target'] * 100))","block_group":"1e2dce3f89014df098b8da1bd1559664","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"4b2cc31d63194e9bb395d397458b12b3","deepnote_cell_type":"code"},"source":"# Predict labels for test data\ny_pred = model_rnn.predict(X_test)\n# Convert predicted probabilities to class labels\ny_pred_classes = np.argmax(y_pred, axis=1)\n# Convert one-hot encoded labels to single labels\ny_true = np.argmax(y_test, axis=1)\n# Calculate F1 score\nf1 = f1_score(y_true, y_pred_classes, average='weighted')","block_group":"9d4a8b1523484cc986622b82578f5519","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2b3c5800-c216-4f08-93af-5173ca1bb328' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"878ace75d52245ac97ca7f6314d0b637","deepnote_execution_queue":[]}}